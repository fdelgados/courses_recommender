{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Courses recommendation system\n",
    "# III. Make recommendations\n",
    "\n",
    "This is the third part of the Udacity Data Science Nanodegree capstone project, which consists in the creation of a course recommendation system.\n",
    "\n",
    "After the exploratory data analysis, is time to play around with structures created in the first part and trying to make recommendations.\n",
    "\n",
    "I will use three types of recommendations:\n",
    "\n",
    "* Knowledge based recommendations\n",
    "* Content based filtering\n",
    "* Neighborhood based collaborative filtering\n",
    "* Model based collaborative filtering\n",
    "\n",
    "## 1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from db_utils import connection\n",
    "from common import requested_courses\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Retrieve data\n",
    "\n",
    "In this step I will retrieve the clean data from database.\n",
    "\n",
    "**Retrieve courses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_query = '''SELECT c.*, cat.name AS category_name FROM courses c \n",
    "                    JOIN categories cat ON c.category_id = cat.id'''\n",
    "\n",
    "courses_df = pd.read_sql_query(courses_query, con=connection())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieve leads**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_query = 'SELECT * FROM clean_leads ORDER BY created_on DESC'\n",
    "\n",
    "leads_df = pd.read_sql_query(leads_query, con=connection())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieve reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_query = 'SELECT * FROM clean_reviews ORDER BY created_on DESC'\n",
    "\n",
    "reviews_df = pd.read_sql_query(reviews_query, con=connection())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Knowledge based recommendations\n",
    "In this type of recommendation, I will use two measures: the most requested courses and the most valued courses by users' ratings. Also, I will add a category filter.\n",
    "\n",
    "### 3.1 Most requested courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_courses_by_leads(df, n=10, category=None):\n",
    "    \"\"\" \n",
    "    Creates an array of n courses ordered by number of leads generated\n",
    "    \n",
    "    :param df DataFrame: Leads dataframe\n",
    "    :param n int: Number of courses in the array\n",
    "    :param category str: If category is supplied, the array will be of courses belonging to that category\n",
    "    \n",
    "    :return numpy.ndarray: Array of top n courses by leads generated\n",
    "    \"\"\" \n",
    "    if category:\n",
    "        df = df[df['category_name'] == category]\n",
    "        \n",
    "    top_courses = df.sort_values('number_of_leads', ascending=False)['title'].head(n)\n",
    "    \n",
    "    return top_courses.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most requested courses:\n",
      "\n",
      "Aviation Engineering - BEng (Hons)\n",
      "Bachelor in Aviation Management\n",
      "MSc Public Health\n",
      "Master of computer science\n",
      "MBA - Engineering Management\n",
      "BA in Hospitality Management\n",
      "MBA - Big Data Management\n",
      "Master of Leadership in Development Finance - Online\n",
      "MBA - Marketing\n",
      "NVQ Tiling courses - Free - Funded by Government\n",
      "\n",
      "Most requested Engineering courses:\n",
      "\n",
      "Aviation Engineering - BEng (Hons)\n",
      "Master of computer science\n",
      "MBA - Engineering Management\n",
      "Master Artificial intelligence\n",
      "Master in Engineering Management\n",
      "BTEC HND Civil Engineering\n",
      "HNC Civil Engineering\n",
      "B.TECH CIVIL ENGINEERING\n",
      "Level 5 Diploma in Civil Engineering\n",
      "Master of Bioscience Engineering: Human Health Engineering (Leuven)\n"
     ]
    }
   ],
   "source": [
    "print('Most requested courses:\\n')\n",
    "print('\\n'.join(get_top_courses_by_leads(courses_df)))\n",
    "\n",
    "print('\\nMost requested Engineering courses:\\n')\n",
    "print('\\n'.join(get_top_courses_by_leads(courses_df, category='Engineering')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Most valued courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_courses_by_rating(df, n=10, category=None):\n",
    "    \"\"\" \n",
    "    Creates an array of n courses ordered by rating\n",
    "    \n",
    "    :param df DataFrame: Reviews dataframe\n",
    "    :param n int: Number of courses in the array\n",
    "    :param category str: If category is supplied, the array will be of courses belonging to that category\n",
    "    :return numpy.ndarray: Array of top n courses by rating\n",
    "    \"\"\"\n",
    "    if category:\n",
    "        df = df[df['category_name'] == category]\n",
    "    \n",
    "    top_courses = df.sort_values(by='weighted_rating', ascending=False)\n",
    "    \n",
    "    return top_courses['title'].values[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most valued courses:\n",
      "\n",
      "Aerospace Engineering MEng (Hons) 4 years\n",
      "Excel Intermediate Course\n",
      "Elite personal training diploma Level 2 & 3\n",
      "MS Project: An Introduction, One-to-one, Classroom based\n",
      "Workplace Wellbeing Champion -Initial Training\n",
      "IPAF Scissor and Boom Training\n",
      "Corporate English Training\n",
      "Safety Harness Awareness and Inspection\n",
      "PASMA Mobile Tower Scaffold \n",
      "NCUK International Foundation Year in Business\n",
      "\n",
      "Most valued courses on Beauty Therapy:\n",
      "\n",
      "Cryotherapy Induced Lipolysis Short Course\n",
      "Ultrasound for Skin Rejuvenation Short Course\n",
      "High Intensity Focused Ultrasound (HIFU) for Face and Neck Short Course\n",
      "Ultrasonic Lipo-Cavitation Short Course\n",
      "Russian Volume Eyelash Extensions\n",
      "LED Light Therapy Short Course\n",
      "Level 4 Radio Frequency for Face and Body Course\n",
      "Radio Frequency for Face and Body Short Course\n",
      "Hair Extensions Business Diploma Course\n",
      "Beauty Therapist Diploma Course\n"
     ]
    }
   ],
   "source": [
    "print('Most valued courses:\\n')\n",
    "print('\\n'.join(get_top_courses_by_rating(courses_df)))\n",
    "\n",
    "print('\\nMost valued courses on Beauty Therapy:\\n')\n",
    "print('\\n'.join(get_top_courses_by_rating(courses_df, category='Beauty Therapy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Content based recommendations\n",
    "\n",
    "Using the courses similarities built in part one, I will make recommendations based on courses title and description.\n",
    "\n",
    "### 4.1 Retrieve similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_sim_query = '''SELECT * FROM courses_similarities'''\n",
    "\n",
    "courses_sims = pd.read_sql_query(courses_sim_query, con=connection())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_courses(course_id, df):\n",
    "    courses = df[df['a_course_id'] == course_id].sort_values('similarity', ascending=False)['another_course_id'].values\n",
    "    \n",
    "    return np.array(courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similar courses to \"Child Care Diploma Level 3\":\n",
      "\n",
      "Working in Child Care\n",
      "Part Time Level 2 Diploma in Child Care and Education\n",
      "CACHE Level 3 Award/Certificate/Diploma in Childcare and Education\n",
      "Child Care Course - Level 3 - Accredited\n",
      "Child Playwork Course - Level 3 - Accredited\n",
      "Level 3 Diploma in Child Care - CPD Certified & IAO Approved\n",
      "Level 3 Diploma in Child Care - Best Seller\n",
      "Professional Diploma in Child Psychology - CPD Certified\n",
      "Child Psychology and Child Care Diploma\n"
     ]
    }
   ],
   "source": [
    "course_id = '170624724'\n",
    "\n",
    "course_name = course_names([course_id])[0]\n",
    "\n",
    "print('\\nSimilar courses to \"{}\":\\n'.format(course_name))\n",
    "print('\\n'.join(course_names(similar_courses(course_id, courses_sims))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content of all these courses seems quite similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Neighborhood based collaborative filtering\n",
    "\n",
    "### 5.1 Using leads data\n",
    "\n",
    "For this recommendations, I will use the leads data. I will find similar users, that is, users that have generated a lead on a course in which a user has just generated a lead. Then, I will look for courses where those users have generated leads and I will recommend them to that user. Something similar to a cross-selling section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_users(user_id, sparse_user_item_dict, min_similarity=1):\n",
    "    \"\"\" \n",
    "    Creates an array of similar users based on leads generated on the same courses\n",
    "    \n",
    "    :param user_id str: User id for which we want to find similar users\n",
    "    :param user_item_matrix DataFrame: Leads user-item matrix\n",
    "                          \n",
    "    :return numpy.array: Array of similar users sorted by similarity\n",
    "    \"\"\"\n",
    "    \n",
    "    user_courses = np.array(sparse_user_item_dict[user_id].todense())[0]\n",
    "    \n",
    "    similarities = dict()\n",
    "    \n",
    "    for another_user_id, another_user_courses in sparse_user_item_dict.items():\n",
    "        if user_id == another_user_id:\n",
    "            continue\n",
    "        \n",
    "        similarity = np.dot(user_courses, np.array(another_user_courses.todense())[0])\n",
    "        if similarity < min_similarity:\n",
    "            continue        \n",
    "                            \n",
    "        similarities[another_user_id] = similarity\n",
    "        \n",
    "\n",
    "    sorted_similarities = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    return np.array([id for (id, similarity) in sorted_similarities])\n",
    "\n",
    "def leads_based_recommendations_for_user(user_id, max_recs=10):\n",
    "    \"\"\" \n",
    "    Returns an array of recommended courses for a user based on generated leads\n",
    "    \n",
    "    :param user_id str: User id for which we want to make the recommendations\n",
    "    :param max_recs int: Maximum number of recommendations\n",
    "                          \n",
    "    :return numpy.array: Array of courses recommended based on generated leads\n",
    "    \"\"\"\n",
    "    \n",
    "    user_courses = requested_courses(user_id, leads_df)\n",
    "    similar_users = find_similar_users(user_id, user_leads_courses_map)\n",
    "\n",
    "    recs = np.array([])\n",
    "\n",
    "    for user in similar_users:\n",
    "        neighbs_leads = requested_courses(user, leads_df)\n",
    "\n",
    "        new_recs = np.setdiff1d(neighbs_leads, user_courses, assume_unique=True)\n",
    "        recs = np.unique(np.concatenate([new_recs, recs], axis=0))\n",
    "\n",
    "        if len(recs) > max_recs:\n",
    "            break\n",
    "\n",
    "    return recs[:max_recs]\n",
    "\n",
    "def course_names(course_ids):\n",
    "    return courses_df[courses_df['id'].isin(course_ids)]['title'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/user_courses_map.pickle', 'rb') as filename:\n",
    "    user_leads_courses_map = pickle.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User courses:\n",
      "['Adobe Photoshop, Illustrator and Graphic Design Bundle Course']\n",
      "\n",
      "Recommended courses:\n",
      "['Enterprise Transformation Maturity Canvas'\n",
      " 'ACCA-Accountancy Traineeship Program' 'HNC Graphic Design'\n",
      " 'Graphics Design and Desktop Publishing'\n",
      " 'Quality Management Systems (QMS) - Lead Auditor'\n",
      " 'Internal Audit - OHSAS 18001 Occupational Health & Safety'\n",
      " 'Advanced Strategic Management'\n",
      " 'Adobe Graphic Design & Web Design Online Training Bundle'\n",
      " 'Professional Diploma in Graphic Design - CPD Certified'\n",
      " 'Auditing and Internal Control Skills']\n"
     ]
    }
   ],
   "source": [
    "user_id = '1460318498c1f53bb880ce2e6d9ef64b'\n",
    "\n",
    "print('User courses:')\n",
    "print(course_names(requested_courses(user_id, leads_df)))\n",
    "\n",
    "print('\\nRecommended courses:')\n",
    "print(course_names(leads_based_recommendations_for_user(user_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the recommender works fine, it makes sense that a user who has generated lead in an Adobe Photoshop course is recommended courses on graphic design and other Adobe products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Using rating data\n",
    "\n",
    "In this seccion, I will use the distances DataFrame built in part one to find the nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_neighbors(user_id, dist_df):\n",
    "    \"\"\"Search for the more similar users to user_id\n",
    "    \n",
    "    :param user: The user_id of the individual you want to find the closest users\n",
    "    :return: An array of the id's of the users sorted from closest to farthest away\n",
    "    \"\"\"\n",
    "    closest_users = dist_df[dist_df['a_user_id'] == user_id].sort_values(by='eucl_distance')['another_user_id']\n",
    "    closest_neighbors = np.array(closest_users)\n",
    "    \n",
    "    return closest_neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendations_by_rating(user_id, dist_df, max_recs=10):\n",
    "    \"\"\"Returns an array of recommended courses for a user based on users ratings\n",
    "    \n",
    "    :param user_id str: User id for which we want to make the recommendations\n",
    "    :param dist_df: Distances DataFrame\n",
    "    :param max_recs int: Maximum number of recommendations\n",
    "    :return numpy.array: Array of courses recommended based on user ratings\n",
    "    \"\"\"\n",
    "    recs = np.array([])\n",
    "    \n",
    "    user_rated_courses = rated_courses(user_id)\n",
    "    closest_neighbors = find_closest_neighbors(user_id, dist_df)\n",
    "    \n",
    "    for neighbor in closest_neighbors:\n",
    "        neighbs_likes = courses_liked(neighbor, 0)\n",
    "        \n",
    "        #Obtain recommendations for each neighbor\n",
    "        new_recs = np.setdiff1d(neighbs_likes, user_rated_courses, assume_unique=True)\n",
    "        \n",
    "        # Update recs with new recs\n",
    "        recs = np.unique(np.concatenate([new_recs, recs], axis=0))\n",
    "        \n",
    "        # If we have enough recommendations exit the loop\n",
    "        if len(recs) > max_recs - 1:\n",
    "            break\n",
    "            \n",
    "    return recs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 'ff4c26ace3459427b7c06c493071d31a'\n",
    "\n",
    "print('User courses:')\n",
    "print(course_names(courses_liked(user_id)))\n",
    "\n",
    "print('\\nRecommendations:')\n",
    "print(course_names(make_recommendations_by_rating(user_id, eucl_distances_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Model based collaborative filtering\n",
    "In this part I will use the leads user-item matrix. Since there are no nan values in that matrix, I can use Singular Value Decomposition from numpy on the matrix.\n",
    "\n",
    "### 6.1 Perform SVD\n",
    "\n",
    "**Get the leads user-item matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_user_item_matrix = pd.read_csv('../data/leads_matrix.csv').set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vt = np.linalg.svd(leads_user_item_matrix)\n",
    "s.shape, u.shape, vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_svd(k):\n",
    "    U_reduced = np.mat(u[:,:k])\n",
    "    Vt_reduced = np.mat(vt[:k,:])\n",
    "    Sigma_reduced = np.eye(k) * s[:k]\n",
    "\n",
    "    return Sigma_reduced, U_reduced, Vt_reduced\n",
    "\n",
    "def reduce_svd_2(k):\n",
    "    U_reduced = np.mat(u[:,:k])\n",
    "    Vt_reduced = np.mat(vt[:k,:])\n",
    "    Sigma_reduced = np.eye(k) * s[:k]\n",
    "    Sigma_sqrt = np.sqrt(Sigma_reduced)\n",
    "\n",
    "    return U_reduced * Sigma_sqrt, Sigma_sqrt * Vt_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following graph we will see how the accuracy improves as we increase the number of lantent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_latent_feats = np.arange(10,1500,20)\n",
    "sum_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s[:k]), u[:, :k], vt[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(leads_user_item_matrix, user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs)/leads_df.shape[0]);\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, order_by, total_size=None, train_size=.8, test_size=.2):\n",
    "    df_size = df.shape[0] if total_size is None else total_size\n",
    "    train_size = int(np.floor(df_size * train_size))\n",
    "    test_size = int(np.floor(df_size * test_size))\n",
    "    \n",
    "    #df = df.sort_values(order_by)\n",
    "    train_set = df.head(train_size)\n",
    "    #test_set = df.iloc[train_size:train_size + test_size]\n",
    "    test_set = df.tail(test_size)\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(leads_df, 'created_on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_item_matrix = create_user_item_matrix(train_df, select_column='course_title', allow_nulls=False)\n",
    "test_user_item_matrix = create_user_item_matrix(test_df, select_column='course_title', allow_nulls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = train_user_item_matrix.index.values\n",
    "train_courses = train_user_item_matrix.columns.values\n",
    "test_idx = test_user_item_matrix.index.values\n",
    "test_courses = test_user_item_matrix.columns.values\n",
    "\n",
    "n_users_preds = len(np.intersect1d(test_idx, train_idx))\n",
    "cold_start_users = len(test_idx) - n_users_preds\n",
    "\n",
    "n_courses_preds = len(np.intersect1d(test_courses, train_courses))\n",
    "cold_start_courses = len(test_courses) - n_courses_preds\n",
    "\n",
    "print('Users we can make predictions for: {}\\n' \\\n",
    "      'Users we cannot make predictions for: {}\\n' \\\n",
    "      'Courses we can make predictions for: {}\\n' \\\n",
    "      'Courses we cannot make predictions for: {}\\n'.format(n_users_preds, cold_start_users, n_courses_preds, cold_start_courses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(u, s, vt, k):\n",
    "    '''\n",
    "    INPUT:\n",
    "    u - user feature matrix\n",
    "    s - test dataframe\n",
    "    vt - item feature matrix\n",
    "    k - number of latent features to keep\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item_matrix - a predictions user-item matrix\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    s_new = np.diag(s[:k])\n",
    "    u_new = u[:, :k]\n",
    "    vt_new = vt[:k, :]\n",
    "    \n",
    "    user_item_matrix = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    return user_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train, s_train, vt_train = np.linalg.svd(train_user_item_matrix)\n",
    "u_train.shape, s_train.shape, vt_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_user_ids = train_user_item_matrix.index.isin(test_idx)\n",
    "common_courses_ids = train_user_item_matrix.columns.isin(test_courses)\n",
    "\n",
    "u_test = u_train[common_user_ids, :]\n",
    "vt_test = vt_train[:, common_courses_ids]\n",
    "\n",
    "u_test.shape, vt_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_item_matrix = test_user_item_matrix.loc[np.intersect1d(test_idx, train_idx), np.intersect1d(test_courses, train_courses)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_latent_feats = np.arange(5,800,10)\n",
    "sum_errs_train = []\n",
    "sum_errs_test = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    user_train_preds = predictions(u_train, s_train, vt_train, k)\n",
    "    user_test_preds = predictions(u_test, s_train, vt_test, k)\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs_train = np.subtract(train_user_item_matrix, user_train_preds)\n",
    "    diffs_test = np.subtract(test_user_item_matrix, user_test_preds)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err_train = np.sum(np.sum(np.abs(diffs_train)))\n",
    "    err_test = np.sum(np.sum(np.abs(diffs_test)))\n",
    "    \n",
    "    sum_errs_train.append(err_train)\n",
    "    sum_errs_test.append(err_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_latent_feats, 1 - (np.array(sum_errs_train)/(train_user_item_matrix.shape[0]*train_user_item_matrix.shape[1])), label='Train set');\n",
    "plt.plot(num_latent_feats, 1 - (np.array(sum_errs_test)/(test_user_item_matrix.shape[0]*test_user_item_matrix.shape[1])), label='Test set');\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
